import streamlit as st
import pydicom
import numpy as np
import cv2
from llama_cpp import Llama
import io
import inspect
import re

# --- å®šæ•°è¨­å®šï¼ŒLLM ãƒ­ãƒ¼ãƒ‰ï¼Œç”»åƒå‡¦ç†é–¢æ•°ç¾¤ï¼ŒFUNCTION_MAPï¼ŒLLM é€£æºé–¢æ•° ---
# --- å®šæ•°è¨­å®š ---
MODEL_PATH = "./Llama-3-ELYZA-JP-8B-Q4_K_M.gguf"
WINDOW_PRESETS = {
    "ã‚«ã‚¹ã‚¿ãƒ ": {}, "è…¹éƒ¨": {"ww": 400, "wl": 50}, "éª¨": {"ww": 2000, "wl": 600},
    "è‚º": {"ww": 1500, "wl": -600}, "è„³": {"ww": 80, "wl": 40},
}

# å½¢æ…‹ç´ å¤‰æ›å‡¦ç†ã‚’1ã¤ã«çµ±åˆ
PROCESSING_KNOWLEDGE = {
    # å¹³æ»‘åŒ–ãƒ»ãƒã‚¤ã‚ºé™¤å»ç³»
    "noise_removal": {
        "title": "ãƒã‚¤ã‚ºé™¤å» (ã‚¬ã‚¦ã‚·ã‚¢ãƒ³)", "keywords": ["ãƒã‚¤ã‚º", "æ»‘ã‚‰ã‹", "ã‚¹ãƒ ãƒ¼ã‚º", "ã‚¶ãƒ©ã‚¶ãƒ©", "å¹³æ»‘åŒ–", "ã‚¬ã‚¦ã‚·ã‚¢ãƒ³", "ã¼ã‹ã™", "ãƒã‚¤ã‚ºé™¤å»"]
    },
    "median_filter": {
        "title": "ãƒã‚¤ã‚ºé™¤å» (ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ³)", "keywords": ["ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ³", "ã”ã¾å¡©ãƒã‚¤ã‚º", "å¡©èƒ¡æ¤’ãƒã‚¤ã‚º", "ä¸­é–“å€¤ãƒ•ã‚£ãƒ«ã‚¿"]
    },
    "bilateral_filter": {
        "title": "ã‚¨ãƒƒã‚¸ä¿æŒå¹³æ»‘åŒ–", "keywords": ["ã‚¨ãƒƒã‚¸ä¿æŒå¹³æ»‘åŒ–", "ã‚¨ãƒƒã‚¸ä¿æŒ", "ãƒã‚¤ãƒ©ãƒ†ãƒ©ãƒ«", "bilateral", "è¼ªéƒ­ã‚’æ®‹ã—ã¦å¹³æ»‘åŒ–", "è¼ªéƒ­ã‚’æ®‹ã—ã¦ãƒã‚¤ã‚ºé™¤å»"]
    },
    "blur": {
        "title": "ã¼ã‹ã— (å¹³å‡åŒ–)", "keywords": ["ã¼ã‹ã—", "ãƒ–ãƒ©ãƒ¼", "å¹³å‡åŒ–"]
    },
    # é®®é‹­åŒ–ãƒ»ã‚¨ãƒƒã‚¸å¼·èª¿ç³»
    "edge_enhancement": {
        "title": "ã‚¨ãƒƒã‚¸å¼·èª¿ (é®®é‹­åŒ–)", "keywords": ["ã‚¨ãƒƒã‚¸å¼·èª¿", "ã‚·ãƒ£ãƒ¼ãƒ—", "é®®æ˜", "ãã£ãã‚Š", "ã¯ã£ãã‚Š", "é®®é‹­åº¦", "é®®é‹­åŒ–", "ã‚·ãƒ£ãƒ¼ãƒ—ãƒã‚¹", "å…ˆé‹­åŒ–"]
    },
    # ã‚¨ãƒƒã‚¸æ¤œå‡ºç³»
    "canny_edge": {
        "title": "ã‚¨ãƒƒã‚¸æ¤œå‡º (Canny)", "keywords": ["canny", "ã‚­ãƒ£ãƒ‹ãƒ¼", "ã‚¨ãƒƒã‚¸æ¤œå‡º", "è¼ªéƒ­æŠ½å‡º", "è¼ªéƒ­ã ã‘", "ç·šç”»", "ã‚¨ãƒƒã‚¸æŠ½å‡º", "å¢ƒç•ŒæŠ½å‡º"]
    },
    "sobel_filter": {
        "title": "ã‚¨ãƒƒã‚¸æ¤œå‡º (Sobel)", "keywords": ["sobel", "ã‚½ãƒ¼ãƒ™ãƒ«", "å‹¾é…", "ä¸€æ¬¡å¾®åˆ†"]
    },
    "laplacian_filter": {
        "title": "ã‚¨ãƒƒã‚¸æ¤œå‡º (ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³)", "keywords": ["laplacian", "ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³", "äºŒæ¬¡å¾®åˆ†"]
    },
    # éšèª¿ãƒ»ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆç³»
    "brightness_contrast": {
        "title": "æ˜ã‚‹ã•ãƒ»ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆ", "keywords": ["ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆ", "æ˜ã‚‹ã•", "æ˜ã‚‹ã", "æš—ã", "ç™½ã", "é»’ã", "è¦‹ã‚„ã™ã", "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦", "ww", "wl", "ãƒ¬ãƒ™ãƒ«"]
    },
    "clahe": {
        "title": "ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·èª¿ (CLAHE)", "keywords": ["clahe", "é©å¿œçš„ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ", "ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·èª¿", "æ˜ç­åŒ–"]
    },
    "histogram_equalization": {
        "title": "ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ å¹³å¦åŒ–", "keywords": ["ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ å¹³å¦åŒ–", "ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ å‡ä¸€åŒ–"]
    },
    "gamma_correction": {
        "title": "ã‚¬ãƒ³ãƒè£œæ­£", "keywords": ["ã‚¬ãƒ³ãƒè£œæ­£", "ã‚¬ãƒ³ãƒ"]
    },
    "invert": {
        "title": "ãƒã‚¬ãƒã‚¸åè»¢", "keywords": ["ãƒã‚¬ãƒã‚¸", "è‰²ã‚’åè»¢", "éšèª¿åè»¢", "åè»¢è¡¨ç¤º", "ãƒã‚¬ãƒã‚¸åè»¢"]
    },
    # é–¾å€¤å‡¦ç†ãƒ»äºŒå€¤åŒ–ç³»
    "thresholding": {
        "title": "äºŒå€¤åŒ– (å˜ç´”é–¾å€¤)", "keywords": ["äºŒå€¤åŒ–", "é–¾å€¤", "ç™½é»’", "å˜ç´”é–¾å€¤"]
    },
    "adaptive_thresholding": {
        "title": "äºŒå€¤åŒ– (é©å¿œçš„é–¾å€¤)", "keywords": ["é©å¿œçš„é–¾å€¤", "å±€æ‰€çš„äºŒå€¤åŒ–"]
    },
    # å½¢æ…‹å­¦çš„å‡¦ç† (çµ±åˆ)
    "morphological": {
        "title": "å½¢æ…‹ç´ å¤‰æ›",
        "keywords": ["å½¢æ…‹ç´ ", "åç¸®", "ç´°ãã™ã‚‹", "ä¾µé£Ÿ", "erode", "è†¨å¼µ", "å¤ªãã™ã‚‹", "dilate", "ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°", "open", "ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°", "close", "ç™½ç‚¹ãƒã‚¤ã‚ºé™¤å»", "é»’ç‚¹ãƒã‚¤ã‚ºé™¤å»"]
    },
    # å¹¾ä½•å­¦çš„å¤‰æ›
    "zoom_in": { "title": "æ‹¡å¤§", "keywords": ["æ‹¡å¤§", "ã‚ºãƒ¼ãƒ ", "å¤§ãã", "ã‚¢ãƒƒãƒ—", "zoom"] },
    "rotate": { "title": "å›è»¢", "keywords": ["å›è»¢", "å›ã—ã¦", "å‘ã", "rotate"] },
    "flip": { "title": "åè»¢", "keywords": ["åè»¢", "è£è¿”ã—", "ãƒŸãƒ©ãƒ¼", "flip"] },
    # ç‰¹å¾´æŠ½å‡ºãƒ»ãã®ä»–
    "draw_contours": { "title": "è¼ªéƒ­æç”»", "keywords": ["è¼ªéƒ­ã‚’æç”»", "è¼ªéƒ­ã®æç”»"] },
    "hough_lines": { "title": "ç›´ç·šæ¤œå‡º (ãƒãƒ•å¤‰æ›)", "keywords": ["ç›´ç·šæ¤œå‡º", "ãƒãƒ•å¤‰æ›", "hough"] },
    "detect_circles": { "title": "å††æ¤œå‡º (ãƒãƒ•å¤‰æ›)", "keywords": ["å††æ¤œå‡º", "ä¸¸", "ã‚µãƒ¼ã‚¯ãƒ«"] },
    "fourier_transform": { "title": "ãƒ•ãƒ¼ãƒªã‚¨å¤‰æ›ã‚¹ãƒšã‚¯ãƒˆãƒ«", "keywords": ["ãƒ•ãƒ¼ãƒªã‚¨", "å‘¨æ³¢æ•°", "ã‚¹ãƒšã‚¯ãƒˆãƒ«", "fft"] }
}

# --- LLM ã®ãƒ­ãƒ¼ãƒ‰ ---
@st.cache_resource
def load_model():
    try:
        st.info("LLM ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­ã§ã™ï¼åˆå›èµ·å‹•æ™‚ã¯æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™...")
        llm = Llama(model_path=MODEL_PATH, n_gpu_layers=-1, n_ctx=4096, verbose=False, chat_format="llama-3")
        st.success("LLM ã®ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        return llm
    except Exception as e:
        st.error(f"ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}ï¼ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ« '{MODEL_PATH}' ãŒæ­£ã—ã„å ´æ‰€ã«ã‚ã‚Šã¾ã™ã‹ï¼Ÿ")
        return None
llm = load_model()

# --- ç”»åƒå‡¦ç†é–¢æ•°ç¾¤ ---
def process_adaptive_thresholding(img_in, block_size=11, C=2):
    gray_8bit = cv2.normalize(img_in, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)
    bs = int(block_size); bs = bs if bs % 2 else bs + 1
    return cv2.adaptiveThreshold(gray_8bit, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, bs, int(C))
def process_bilateral_filter(img_in, d=9, sigma_color=75.0, sigma_space=75.0):
    img_float32 = img_in.astype(np.float32) / 65535.0; sigma_color_normalized = sigma_color / 255.0
    filtered_float32 = cv2.bilateralFilter(img_float32, int(d), sigma_color_normalized, sigma_space); return np.clip(filtered_float32 * 65535.0, 0, 65535).astype(np.uint16)
def process_blur(img_in, kernel_size=9):
    k = int(kernel_size); return cv2.GaussianBlur(img_in, (k if k % 2 else k + 1, k if k % 2 else k + 1), 0)
def process_brightness_contrast(img_in, alpha=1.0, beta=0.0): return np.clip(img_in.astype(np.float64) * alpha + beta, 0, 65535).astype(np.uint16)
def process_canny_edge(img_in, threshold1=100, threshold2=200):
    gray_8bit = cv2.normalize(img_in, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U); return cv2.Canny(gray_8bit, int(threshold1), int(threshold2))
def process_clahe(img_in, clip_limit=2.0, tile_grid_size=8):
    gray_8bit = cv2.normalize(img_in, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)
    clahe = cv2.createCLAHE(clipLimit=float(clip_limit), tileGridSize=(int(tile_grid_size), int(tile_grid_size)))
    return clahe.apply(gray_8bit)
def process_detect_bounding_box(img_in):
    output_img = cv2.normalize(img_in, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U); output_img = cv2.cvtColor(output_img, cv2.COLOR_GRAY2BGR)
    gray_8bit = output_img[:,:,0]; _, thresh = cv2.threshold(gray_8bit, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if contours: largest_contour = max(contours, key=cv2.contourArea); x, y, w, h = cv2.boundingRect(largest_contour); cv2.rectangle(output_img, (x, y), (x + w, y + h), (0, 255, 0), 3)
    return output_img
def process_detect_circles(img_in, dp=1.2, min_dist=100, param1=50, param2=30, min_radius=10, max_radius=100):
    output_img = cv2.normalize(img_in, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U); output_img = cv2.cvtColor(output_img, cv2.COLOR_GRAY2BGR)
    gray_8bit = output_img[:,:,0]; gray_8bit = cv2.medianBlur(gray_8bit, 5)
    circles = cv2.HoughCircles(gray_8bit, cv2.HOUGH_GRADIENT, dp=dp, minDist=min_dist, param1=param1, param2=param2, minRadius=min_radius, maxRadius=max_radius)
    if circles is not None:
        circles = np.uint16(np.around(circles));
        for i in circles[0, :]: center = (i[0], i[1]); radius = i[2]; cv2.circle(output_img, center, radius, (255, 0, 255), 3); cv2.circle(output_img, center, 2, (255, 255, 0), 3)
    return output_img
def process_draw_contours(img_in, threshold=127.0, thickness=2):
    gray_8bit = cv2.normalize(img_in, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U); _, thresh_img = cv2.threshold(gray_8bit, int(threshold), 255, cv2.THRESH_BINARY)
    contours, _ = cv2.findContours(thresh_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE); output_img = cv2.cvtColor(gray_8bit, cv2.COLOR_GRAY2BGR)
    cv2.drawContours(output_img, contours, -1, (0, 255, 0), int(thickness)); return output_img
def process_edge_enhancement(img_in, strength=1.5):
    img_float = img_in.astype(np.float64); blurred_float = cv2.GaussianBlur(img_float, (3, 3), 0)
    weight = float(strength) - 1.0; enhanced_float = np.clip(img_float + weight * (img_float - blurred_float), 0, 65535)
    return enhanced_float.astype(np.uint16)
def process_flip(img_in, direction="å·¦å³åè»¢"):
    flip_map = {"å·¦å³åè»¢": 1, "ä¸Šä¸‹åè»¢": 0, "ä¸¡æ–¹": -1}; return cv2.flip(img_in, flip_map[direction])
def process_fourier_transform(img_in):
    img_float = img_in.astype(np.float32)
    dft = cv2.dft(img_float, flags=cv2.DFT_COMPLEX_OUTPUT)
    dft_shift = np.fft.fftshift(dft)
    magnitude_spectrum = 20 * np.log(cv2.magnitude(dft_shift[:, :, 0], dft_shift[:, :, 1]) + 1)
    return cv2.normalize(magnitude_spectrum, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)
def process_gamma_correction(img_in, gamma=1.0):
    g = float(gamma) if gamma > 0 else 0.1
    inv_gamma = 1.0 / g
    table = np.array([((i / 65535.0) ** inv_gamma) * 65535 for i in np.arange(0, 65536)]).astype("uint16")
    return cv2.LUT(img_in, table)
def process_histogram_equalization(img_in):
    gray_8bit = cv2.normalize(img_in, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)
    return cv2.equalizeHist(gray_8bit)
def process_hough_lines(img_in, rho=1, theta_deg=1, threshold=100, min_line_length=50, max_line_gap=10):
    gray_8bit = cv2.normalize(img_in, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)
    edges = cv2.Canny(gray_8bit, 50, 150, apertureSize=3)
    output_img = cv2.cvtColor(gray_8bit, cv2.COLOR_GRAY2BGR)
    theta_rad = np.deg2rad(float(theta_deg))
    lines = cv2.HoughLinesP(edges, float(rho), theta_rad, int(threshold), minLineLength=int(min_line_length), maxLineGap=int(max_line_gap))
    if lines is not None:
        for line in lines:
            x1, y1, x2, y2 = line[0]; cv2.line(output_img, (x1, y1), (x2, y2), (0, 0, 255), 2)
    return output_img
def process_invert(img_in):
    if img_in.dtype == np.uint16: return 65535 - img_in
    else: return 255 - img_in
def process_laplacian_filter(img_in, ksize=3):
    gray_8bit = cv2.normalize(img_in, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)
    k = int(ksize); k = k if k % 2 else k + 1
    laplacian = cv2.Laplacian(gray_8bit, cv2.CV_64F, ksize=k)
    return cv2.convertScaleAbs(laplacian)
def process_median_filter(img_in, kernel_size=5):
    k = int(kernel_size); return cv2.medianBlur(img_in, k if k % 2 else k + 1)
def process_morphological(img_in, operation="ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°", kernel_size=5):
    gray_8bit = cv2.normalize(img_in, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U); kernel = np.ones((int(kernel_size), int(kernel_size)), np.uint8)
    op_map = {"ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°": cv2.MORPH_OPEN, "ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°": cv2.MORPH_CLOSE, "è†¨å¼µ": cv2.MORPH_DILATE, "åç¸®": cv2.MORPH_ERODE}; return cv2.morphologyEx(gray_8bit, op_map[operation], kernel)
def process_noise_removal(img_in, kernel_size=5):
    k = int(kernel_size); return cv2.GaussianBlur(img_in, (k if k % 2 else k + 1, k if k % 2 else k + 1), 0)
def process_rotate(img_in, angle="90åº¦ å³"):
    angle_map = {"90åº¦ å³": cv2.ROTATE_90_CLOCKWISE, "90åº¦ å·¦": cv2.ROTATE_90_COUNTERCLOCKWISE, "180åº¦": cv2.ROTATE_180}; return cv2.rotate(img_in, angle_map[angle])
def process_sobel_filter(img_in, ksize=3):
    gray_8bit = cv2.normalize(img_in, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)
    k = int(ksize); k = k if k % 2 else k + 1
    sobelx = cv2.Sobel(gray_8bit, cv2.CV_64F, 1, 0, ksize=k)
    sobely = cv2.Sobel(gray_8bit, cv2.CV_64F, 0, 1, ksize=k)
    sobel_abs = np.sqrt(sobelx**2 + sobely**2)
    return cv2.normalize(sobel_abs, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)
def process_thresholding(img_in, threshold_value=127.0):
    gray_8bit = cv2.normalize(img_in, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U); _, thresh_img = cv2.threshold(gray_8bit, int(threshold_value), 255, cv2.THRESH_BINARY); return thresh_img
def process_zoom_in(img_in, scale=2.0, offset_x=0.0, offset_y=0.0):
    h, w = img_in.shape[:2]; center_x = w // 2 + int(offset_x * w / 2); center_y = h // 2 + int(offset_y * h / 2)
    new_w, new_h = int(w / scale), int(h / scale); x1 = max(0, center_x - new_w // 2); y1 = max(0, center_y - new_h // 2)
    x2, y2 = min(w, x1 + new_w), min(h, y1 + new_h)
    if x2 - x1 < new_w: x1 = x2 - new_w
    if y2 - y1 < new_h: y1 = y2 - new_h
    cropped = img_in[y1:y2, x1:x2]; return cv2.resize(cropped, (w, h), interpolation=cv2.INTER_LANCZOS4)


FUNCTION_MAP = {k: {"func": globals()[f"process_{k}"], **v} for k, v in PROCESSING_KNOWLEDGE.items()}

def get_tasks_from_llm(user_instruction):
    if llm is None:
        st.warning("LLM ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã§ä»£ç”¨ã—ã¾ã™ï¼");
        tasks = [name for name, info in FUNCTION_MAP.items() if any(keyword in user_instruction for keyword in info['keywords'])];
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã§ã‚‚é‡è¤‡ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ï¼Œé †åºã‚’ä¿æŒã—ã¤ã¤é‡è¤‡ã‚’å‰Šé™¤
        return list(dict.fromkeys(tasks)) if tasks else []

    task_list = "\n".join([f"- `{name}`: {info['title']}" for name, info in FUNCTION_MAP.items()])
    
    # æ”¹å–„ã•ã‚ŒãŸã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    system_prompt = f"""ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŒ‡ç¤ºã‚’åˆ†æã—ï¼Œå®Ÿè¡Œã™ã¹ãå‡¦ç†ã‚’é †ç•ªã«ç‰¹å®šã™ã‚‹å°‚é–€å®¶ã§ã™ï¼ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦ï¼Œã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆã‹ã‚‰é©åˆ‡ãªã‚¿ã‚¹ã‚¯åã‚’1ã¤ä»¥ä¸Šé¸ã³ï¼Œã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®ãƒªã‚¹ãƒˆã¨ã—ã¦è¿”ç­”ã—ã¦ãã ã•ã„ï¼

### ãƒ«ãƒ¼ãƒ« ###
1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŒ‡ç¤ºã«æœ€ã‚‚åˆè‡´ã™ã‚‹ã‚¿ã‚¹ã‚¯ã‚’ï¼Œå¿…è¦æœ€å°é™ã®æ•°ã ã‘é¸ã‚“ã§ãã ã•ã„ï¼
2. ä¼¼ãŸã‚ˆã†ãªç›®çš„ã®ã‚¿ã‚¹ã‚¯ãŒè¤‡æ•°ã‚ã‚‹å ´åˆï¼Œã‚ˆã‚ŠåŸºæœ¬çš„ã§ä¸€èˆ¬çš„ãªã‚¿ã‚¹ã‚¯ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼
   - ä¾‹ãˆã°ï¼Œã€Œå¹³æ»‘åŒ–ã€ã€Œãƒã‚¤ã‚ºé™¤å»ã€ã¨ã„ã†ä¸€èˆ¬çš„ãªæŒ‡ç¤ºã«ã¯ï¼Œã¾ãš`noise_removal`ã‚’é¸æŠã—ã¾ã™ï¼
   - ã€Œã‚¨ãƒƒã‚¸ã‚’ä¿æŒã—ãªãŒã‚‰å¹³æ»‘åŒ–ã€ã€Œãƒã‚¤ãƒ©ãƒ†ãƒ©ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ã€ã®ã‚ˆã†ã«ï¼Œãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ˜ç¢ºã«é«˜åº¦ãªå‡¦ç†ã‚’æŒ‡å®šã—ãŸå ´åˆã«ã®ã¿ï¼Œ`bilateral_filter`ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼
3. ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ„å›³ã—ã¦ã„ãªã„ä½™è¨ˆãªå‡¦ç†ã¯çµ¶å¯¾ã«è¿½åŠ ã—ãªã„ã§ãã ã•ã„ï¼

### ã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆ ###
{task_list}

### æŒ‡ç¤ºã¨å›ç­”ã®ä¾‹ ###
- æŒ‡ç¤º: ã€Œãƒã‚¤ã‚ºã‚’æ¶ˆã—ã¦ã€ -> å›ç­”: `noise_removal`
- æŒ‡ç¤º: ã€Œå¹³æ»‘åŒ–ã—ã¦ã‚¨ãƒƒã‚¸æ¤œå‡ºã€ -> å›ç­”: `noise_removal,canny_edge`
- æŒ‡ç¤º: ã€Œè¼ªéƒ­ã‚’ã¯ã£ãã‚Šã•ã›ã¦ã‹ã‚‰ï¼Œã‚¨ãƒƒã‚¸ã‚’æ¤œå‡ºã—ã¦ã€ -> å›ç­”: `edge_enhancement,canny_edge`
- æŒ‡ç¤º: ã€Œæ‹¡å¤§ã—ã¦ï¼Œæ»‘ã‚‰ã‹ã«ã—ã¦ã»ã—ã„ã€ -> å›ç­”: `zoom_in,noise_removal`
- æŒ‡ç¤º: ã€Œã‚¨ãƒƒã‚¸ã¯æ®‹ã—ã¦æ»‘ã‚‰ã‹ã«ã€ -> å›ç­”: `bilateral_filter`
- æŒ‡ç¤º: ã€Œç”»åƒã‚’å¹³æ»‘åŒ–ã—ã¦ã€ -> å›ç­”: `noise_removal`
- æŒ‡ç¤º: ã€Œåç¸®ã—ã¦ã€ -> å›ç­”: `morphological`
"""
    messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_instruction}]
    try:
        output = llm.create_chat_completion(messages=messages, max_tokens=100, temperature=0.0)
        content = output['choices'][0]['message']['content'].strip()
        st.session_state.debug_llm_response = content
        all_task_names = list(FUNCTION_MAP.keys())
        pattern = r'\b(' + '|'.join(all_task_names) + r')\b'
        found_tasks = re.findall(pattern, content)
        # LLM ãŒèª¤ã£ã¦é‡è¤‡ã—ãŸã‚¿ã‚¹ã‚¯ã‚’è¿”ã™å¯èƒ½æ€§ã«å‚™ãˆï¼Œã“ã“ã§é‡è¤‡ã‚’å‰Šé™¤ã™ã‚‹
        return list(dict.fromkeys(found_tasks)) if found_tasks else []
    except Exception as e:
        st.error(f"AI ã®å¿œç­”å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"); return []


def convert_to_16bit_gray(pixel_array):
    if len(pixel_array.shape) > 2: pixel_array = cv2.cvtColor(pixel_array, cv2.COLOR_BGR2GRAY)
    if pixel_array.dtype != np.uint16: pixel_array = cv2.normalize(pixel_array.astype(float), None, 0, 65535, cv2.NORM_MINMAX).astype(np.uint16)
    return pixel_array
def apply_ww_wl_and_convert_to_bgr(pixel_array, ww, wl, enhance=False):
    if pixel_array is None: return None
    if pixel_array.dtype == np.uint8: return cv2.cvtColor(pixel_array, cv2.COLOR_GRAY2BGR) if len(pixel_array.shape) == 2 else pixel_array
    min_val, max_val = wl - (ww / 2), wl + (ww / 2); img_float = pixel_array.astype(np.float64); img_float = np.clip(img_float, min_val, max_val)
    if ww == 0: ww = 1
    img_8bit_gray = ((img_float - min_val) / ww * 255.0).astype(np.uint8)
    if enhance: clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)); img_8bit_gray = clahe.apply(img_8bit_gray)
    return cv2.cvtColor(img_8bit_gray, cv2.COLOR_GRAY2BGR)


st.set_page_config(layout="wide", page_title="LLM åŒ»ç”¨ç”»åƒå‡¦ç†")
st.title("LLM åŒ»ç”¨ç”»åƒå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ")

PARAM_CONFIG = {
    "noise_removal": {"kernel_size": {"label": "é™¤å»å¼·åº¦", "min": 3, "max": 41, "step": 2, "default": 15}},
    "median_filter": {"kernel_size": {"label": "ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º", "min": 3, "max": 41, "step": 2, "default": 5}},
    "bilateral_filter": {"d": {"label": "è¿‘å‚é ˜åŸŸã®ç›´å¾„", "min": 1, "max": 15, "step": 2, "default": 9}, "sigma_color": {"label": "è¼åº¦å·®ã®è¨±å®¹ç¯„å›²", "min": 1.0, "max": 255.0, "default": 75.0}, "sigma_space": {"label": "ç©ºé–“è·é›¢ã®è¨±å®¹ç¯„å›²", "min": 1.0, "max": 255.0, "default": 75.0}},
    "blur": {"kernel_size": {"label": "ã¼ã‹ã—å¼·åº¦", "min": 3, "max": 41, "step": 2, "default": 15}},
    "edge_enhancement": {"strength": {"label": "å¼·èª¿åº¦", "min": 1.1, "max": 5.0, "step": 0.1, "default": 2.5}},
    "canny_edge": {"threshold1": {"label": "ä¸‹ä½é–¾å€¤", "min": 0, "max": 500, "default": 100}, "threshold2": {"label": "ä¸Šä½é–¾å€¤", "min": 0, "max": 500, "default": 200}},
    "sobel_filter": {"ksize": {"label": "ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º", "min": 3, "max": 31, "step": 2, "default": 3}},
    "laplacian_filter": {"ksize": {"label": "ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º", "min": 3, "max": 31, "step": 2, "default": 3}},
    "brightness_contrast": {"alpha": {"label": "ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆ", "min": 0.1, "max": 3.0, "step": 0.1, "default": 1.0}, "beta": {"label": "æ˜ã‚‹ã•", "min": -10000.0, "max": 10000.0, "step": 100.0, "default": 0.0}},
    "clahe": {"clip_limit": {"label": "ã‚¯ãƒªãƒƒãƒ—ä¸Šé™", "min": 1.0, "max": 10.0, "step": 0.5, "default": 2.0}, "tile_grid_size": {"label": "ã‚¿ã‚¤ãƒ«ã‚µã‚¤ã‚º", "min": 2, "max": 16, "default": 8}},
    "gamma_correction": {"gamma": {"label": "ã‚¬ãƒ³ãƒå€¤", "min": 0.1, "max": 3.0, "step": 0.1, "default": 1.0}},
    "thresholding": {"threshold_value": {"label": "é–¾å€¤", "min": 0.0, "max": 255.0, "default": 127.0}},
    "adaptive_thresholding": {"block_size": {"label": "ãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚º", "min": 3, "max": 51, "step": 2, "default": 11}, "C": {"label": "å®šæ•°C", "min": -10, "max": 10, "default": 2}},
    "morphological": {"operation": {"type": "selectbox", "label": "æ“ä½œã‚¿ã‚¤ãƒ—", "options": ["ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°", "ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°", "è†¨å¼µ", "åç¸®"], "default": "ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°"}, "kernel_size": {"label": "ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º", "min": 3, "max": 21, "step": 2, "default": 5}},
    "zoom_in": {"scale": {"label": "æ‹¡å¤§ç‡", "min": 1.1, "max": 10.0, "step": 0.1, "default": 2.0}, "offset_x": {"label": "Xåº§æ¨™ã‚ªãƒ•ã‚»ãƒƒãƒˆ", "min": -1.0, "max": 1.0, "step": 0.05, "default": 0.0}, "offset_y": {"label": "Yåº§æ¨™ã‚ªãƒ•ã‚»ãƒƒãƒˆ", "min": -1.0, "max": 1.0, "step": 0.05, "default": 0.0}},
    "rotate": {"angle": {"type": "selectbox", "label": "å›è»¢è§’åº¦", "options": ["90åº¦ å³", "90åº¦ å·¦", "180åº¦"], "default": "90åº¦ å³"}},
    "flip": {"direction": {"type": "selectbox", "label": "åè»¢æ–¹å‘", "options": ["å·¦å³åè»¢", "ä¸Šä¸‹åè»¢", "ä¸¡æ–¹"], "default": "å·¦å³åè»¢"}},
    "draw_contours": {"threshold": {"label": "äºŒå€¤åŒ–é–¾å€¤", "min": 0.0, "max": 255.0, "default": 127.0}, "thickness": {"label": "è¼ªéƒ­ã®å¤ªã•", "min": 1, "max": 10, "default": 2}},
    "hough_lines": {"rho": {"label": "Rho (è·é›¢åˆ†è§£èƒ½)", "min": 1, "max": 10, "default": 1}, "theta_deg": {"label": "Theta (è§’åº¦åˆ†è§£èƒ½)", "min": 1, "max": 10, "default": 1}, "threshold": {"label": "é–¾å€¤", "min": 10, "max": 200, "default": 100}, "min_line_length": {"label": "æœ€å°ã®ç·šé•·", "min": 10, "max": 200, "default": 50}, "max_line_gap": {"label": "æœ€å¤§ç·šé–“ã‚®ãƒ£ãƒƒãƒ—", "min": 1, "max": 50, "default": 10}},
    "detect_circles": {"dp": {"label": "dp", "min": 1.0, "max": 2.0, "step": 0.1, "default": 1.2}, "min_dist": {"label": "å††åŒå£«ã®æœ€å°è·é›¢", "min": 10, "max": 200, "default": 100}, "param1": {"label": "Cannyä¸Šä½é–¾å€¤", "min": 10, "max": 200, "default": 50}, "param2": {"label": "æ¤œå‡ºæ„Ÿåº¦", "min": 10, "max": 100, "default": 30}, "min_radius": {"label": "æœ€å°åŠå¾„", "min": 0, "max": 200, "default": 10}, "max_radius": {"label": "æœ€å¤§åŠå¾„", "min": 0, "max": 500, "default": 100}},
}
def reset_all_params_to_default():
    for task, params in PARAM_CONFIG.items():
        for param_name, config in params.items(): st.session_state[f"p_{task}_{param_name}"] = config["default"]

def handle_instruction_submit():
    """æŒ‡ç¤ºãŒé€ä¿¡ã•ã‚ŒãŸã¨ãã«å®Ÿè¡Œã•ã‚Œã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°"""
    if 'debug_llm_response' in st.session_state:
        del st.session_state['debug_llm_response']

    instruction = st.session_state.get("instruction_input", "").strip()

    if not instruction:
        st.session_state.last_tasks = []
        reset_all_params_to_default()
        st.toast("ç”»åƒå‡¦ç†ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸï¼")
    else:
        st.toast("AIãŒã‚¿ã‚¹ã‚¯ã‚’è§£æä¸­...")
        task_names = get_tasks_from_llm(instruction)
        
        # get_tasks_from_llmå†…ã§é‡è¤‡å‰Šé™¤ã¯è¡Œã‚ã‚Œã¦ã„ã‚‹ãŒï¼Œå¿µã®ãŸã‚ã“ã“ã§ã‚‚ãƒã‚§ãƒƒã‚¯
        if task_names:
            task_names = list(dict.fromkeys(task_names))

        if st.session_state.get("last_tasks", []) != task_names:
            reset_all_params_to_default()

        st.session_state.last_tasks = task_names

        if task_names:
            titles = " â†’ ".join([FUNCTION_MAP[t]['title'] for t in task_names])
            st.toast(f"âœ… ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­å®š: {titles}")
        else:
            st.session_state.show_task_not_found_error = True

# --- çŠ¶æ…‹ã®åˆæœŸåŒ– ---
if "initialized" not in st.session_state:
    st.session_state.initialized = True
    st.session_state.last_tasks = []
    st.session_state.last_file_id = None
    st.session_state.p_ww = 400.0
    st.session_state.p_wl = 50.0
    st.session_state.preset = "ã‚«ã‚¹ã‚¿ãƒ "
    reset_all_params_to_default()

# --- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨DICOMèª­ã¿è¾¼ã¿ ---
uploaded_file = st.file_uploader("16-bit DICOMç”»åƒã‚’é¸æŠ", type=["dcm", "dicom"])
original_16bit_gray = None
if uploaded_file:
    if st.session_state.last_file_id != uploaded_file.file_id:
        st.session_state.last_tasks = []
        st.session_state.dicom_ww_wl_initialized = False
        if 'instruction_input' in st.session_state: st.session_state.instruction_input = ""
        st.session_state.last_file_id = uploaded_file.file_id
    try:
        ds = pydicom.dcmread(io.BytesIO(uploaded_file.getvalue()))
        pixel_array = ds.pixel_array * ds.get("RescaleSlope", 1) + ds.get("RescaleIntercept", 0)
        original_16bit_gray = convert_to_16bit_gray(pixel_array)
        if not st.session_state.get('dicom_ww_wl_initialized', False):
            try:
                wl_val = ds.WindowCenter[0] if isinstance(ds.WindowCenter, pydicom.multival.MultiValue) else ds.WindowCenter
                ww_val = ds.WindowWidth[0] if isinstance(ds.WindowWidth, pydicom.multival.MultiValue) else ds.WindowWidth
                st.session_state.initial_wl, st.session_state.initial_ww = float(wl_val), float(ww_val)
            except (AttributeError, TypeError, IndexError):
                min_val, max_val = np.min(original_16bit_gray), np.max(original_16bit_gray)
                st.session_state.initial_ww = float(max_val - min_val if max_val > min_val else 1)
                st.session_state.initial_wl = float(min_val + st.session_state.initial_ww / 2)
            
            st.session_state.p_wl, st.session_state.p_ww = st.session_state.initial_wl, st.session_state.initial_ww
            st.session_state.p_wl_slider, st.session_state.p_ww_slider = st.session_state.initial_wl, st.session_state.initial_ww
            st.session_state.dicom_ww_wl_initialized = True
    except Exception as e:
        st.error(f"DICOMèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        original_16bit_gray = None

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼UI ---
with st.sidebar:
    st.header("ğŸ–¼ï¸ è¡¨ç¤ºã‚ªãƒ—ã‚·ãƒ§ãƒ³")
    enhance_default = st.checkbox("ç”»è³ªã‚’å‘ä¸Šã•ã›ã‚‹ (CLAHE)", value=False)
    st.header("è¡¨ç¤ºèª¿æ•´ (WW/WL)")
    is_disabled = (original_16bit_gray is None)
    
    def reset_ww_wl():
        if "initial_ww" in st.session_state and "initial_wl" in st.session_state:
            st.session_state.p_ww, st.session_state.p_wl = st.session_state.initial_ww, st.session_state.initial_wl
            st.session_state.p_ww_slider, st.session_state.p_wl_slider = st.session_state.initial_ww, st.session_state.initial_wl

    def on_preset_change():
        preset_key = st.session_state.preset
        if preset_key != "ã‚«ã‚¹ã‚¿ãƒ " and preset_key in WINDOW_PRESETS:
            st.session_state.p_ww, st.session_state.p_wl = float(WINDOW_PRESETS[preset_key]["ww"]), float(WINDOW_PRESETS[preset_key]["wl"])
            st.session_state.p_ww_slider, st.session_state.p_wl_slider = st.session_state.p_ww, st.session_state.p_wl

    st.selectbox("ãƒ—ãƒªã‚»ãƒƒãƒˆ", list(WINDOW_PRESETS.keys()), key="preset", on_change=on_preset_change, disabled=is_disabled)

    WW_MIN, WW_MAX, WL_MIN, WL_MAX = 1.0, 65536.0, -32768.0, 65536.0
    
    def sync_ww_from_slider(): st.session_state.p_ww = st.session_state.p_ww_slider; st.session_state.preset = "ã‚«ã‚¹ã‚¿ãƒ "
    def sync_ww_from_number_input(): st.session_state.p_ww_slider = st.session_state.p_ww
    def sync_wl_from_slider(): st.session_state.p_wl = st.session_state.p_wl_slider; st.session_state.preset = "ã‚«ã‚¹ã‚¿ãƒ "
    def sync_wl_from_number_input(): st.session_state.p_wl_slider = st.session_state.p_wl

    if 'p_ww_slider' not in st.session_state: st.session_state.p_ww_slider = st.session_state.p_ww
    if 'p_wl_slider' not in st.session_state: st.session_state.p_wl_slider = st.session_state.p_wl

    col1, col2 = st.columns([0.4, 0.6])
    with col1: st.number_input("WW", WW_MIN, WW_MAX, key="p_ww", disabled=is_disabled, step=10.0, format="%.1f", on_change=sync_ww_from_number_input)
    with col2: st.slider(" ", WW_MIN, WW_MAX, key="p_ww_slider", label_visibility="collapsed", disabled=is_disabled, on_change=sync_ww_from_slider)
    col3, col4 = st.columns([0.4, 0.6])
    with col3: st.number_input("WL", WL_MIN, WL_MAX, key="p_wl", disabled=is_disabled, step=10.0, format="%.1f", on_change=sync_wl_from_number_input)
    with col4: st.slider(" ", WL_MIN, WL_MAX, key="p_wl_slider", label_visibility="collapsed", disabled=is_disabled, on_change=sync_wl_from_slider)
    st.button("WW/WLã‚’åˆæœŸå€¤ã«æˆ»ã™", on_click=reset_ww_wl, disabled=is_disabled, use_container_width=True)
    
    st.header("âš™ï¸ å‡¦ç†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´")
    tasks = st.session_state.get("last_tasks", [])
    if original_16bit_gray is not None and tasks:
        for i, task in enumerate(tasks):
            task_config = PARAM_CONFIG.get(task)
            with st.expander(f"ã‚¹ãƒ†ãƒƒãƒ— {i+1}: {FUNCTION_MAP[task]['title']}", expanded=True):
                if task_config:
                    for param_name, config in task_config.items():
                        session_key = f"p_{task}_{param_name}"
                        if config.get("type") == "selectbox": st.selectbox(config["label"], config["options"], key=session_key)
                        else: st.slider(config["label"], config["min"], config["max"], step=config.get("step", 0.1 if isinstance(config["min"], float) else 1), key=session_key)
                else: st.info("èª¿æ•´å¯èƒ½ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ï¼")
        st.button("å…¨ã¦ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’åˆæœŸå€¤ã«æˆ»ã™", on_click=reset_all_params_to_default, use_container_width=True)
    else: st.info("å‡¦ç†ã‚’é¸æŠã™ã‚‹ã¨ï¼Œèª¿æ•´é …ç›®ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ï¼")

# --- ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ã®UIã¨å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯ ---
if original_16bit_gray is not None:
    st.text_input(
        "ç”»åƒå‡¦ç†ã®æŒ‡ç¤º",
        placeholder="ä¾‹: æ‹¡å¤§ã—ã¦å¹³æ»‘åŒ– / ç©ºæ¬„ã§ãƒªã‚»ãƒƒãƒˆ",
        key="instruction_input",
        label_visibility="collapsed",
        on_change=handle_instruction_submit
    )
    st.button(
        label='ç”»åƒå‡¦ç†ã‚’å®Ÿè¡Œ',
        use_container_width=True,
        disabled=(llm is None),
        on_click=handle_instruction_submit
    )
    
    if st.session_state.get("show_task_not_found_error", False):
        st.error("æŒ‡ç¤ºå†…å®¹ã«å¯¾å¿œã™ã‚‹å‡¦ç†ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼")
        st.session_state.show_task_not_found_error = False
    
    if 'debug_llm_response' in st.session_state and st.session_state.debug_llm_response:
        with st.expander("ãƒ‡ãƒãƒƒã‚°æƒ…å ±: AIã‹ã‚‰ã®ç”Ÿã®å¿œç­”"):
            st.text(st.session_state.debug_llm_response)

    if llm is None: st.warning("LLM ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„ãŸã‚ï¼ŒæŒ‡ç¤ºã«ã‚ˆã‚‹ç”»åƒå‡¦ç†ã¯ç„¡åŠ¹ã§ã™ï¼")

    tasks_to_run = st.session_state.get("last_tasks", [])
    display_original_image = original_16bit_gray
    if tasks_to_run and tasks_to_run[0] == 'zoom_in':
        zoom_params = {p_name: st.session_state[f"p_zoom_in_{p_name}"]
                       for p_name in inspect.signature(process_zoom_in).parameters
                       if p_name != 'img_in' and f"p_zoom_in_{p_name}" in st.session_state}
        display_original_image = process_zoom_in(original_16bit_gray, **zoom_params)

    processed_image = original_16bit_gray
    header_text = "å‡¦ç†å¾Œ"
    if tasks_to_run:
        header_text = f"å‡¦ç†å¾Œ: " + " â†’ ".join([FUNCTION_MAP[t]['title'] for t in tasks_to_run])
    temp_image = original_16bit_gray.copy()
    if tasks_to_run:
        try:
            for task in tasks_to_run:
                processing_function = FUNCTION_MAP[task]["func"]
                params_to_pass = {param_name: st.session_state[f"p_{task}_{param_name}"]
                                  for param_name in inspect.signature(processing_function).parameters
                                  if param_name != 'img_in' and f"p_{task}_{param_name}" in st.session_state}
                temp_image = processing_function(temp_image, **params_to_pass)
            processed_image = temp_image
        except Exception as e:
            st.error(f"ç”»åƒå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"); st.exception(e)
            
    col1, col2 = st.columns(2)
    ww, wl = st.session_state.p_ww, st.session_state.p_wl
    
    # st.headerã®ä»£ã‚ã‚Šã«st.markdownã‚’ä½¿ã„ï¼ŒCSSã§ã‚¹ã‚¿ã‚¤ãƒ«ã‚’èª¿æ•´
    header_style = "font-weight: 600; font-size: 1.7rem; margin-bottom: 1rem;"

    with col1:
        # å·¦å´ã®ãƒ˜ãƒƒãƒ€ãƒ¼
        st.markdown(f'<p style="{header_style}">å‡¦ç†å‰</p>', unsafe_allow_html=True)
        st.image(apply_ww_wl_and_convert_to_bgr(display_original_image, ww, wl, enhance=enhance_default), use_container_width=True)
    
    with col2:
        # å³å´ã®ãƒ˜ãƒƒãƒ€ãƒ¼ã«æ”¹è¡Œé˜²æ­¢ã¨çœç•¥(...)ã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’è¿½åŠ 
        # titleå±æ€§ã«å…¨æ–‡ã‚’å…¥ã‚Œã‚‹ã“ã¨ã§ï¼Œãƒã‚¦ã‚¹ã‚ªãƒ¼ãƒãƒ¼ã§å…¨æ–‡ã‚’ç¢ºèªã§ãã‚‹
        st.markdown(
            f'<p style="{header_style} white-space: nowrap; overflow: hidden; text-overflow: ellipsis;" title="{header_text}">{header_text}</p>',
            unsafe_allow_html=True
        )
        st.image(apply_ww_wl_and_convert_to_bgr(processed_image, ww, wl, enhance=enhance_default), use_container_width=True)
else:
    if not uploaded_file: st.info("DICOM ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ï¼Œç”»åƒå‡¦ç†ã‚’é–‹å§‹ã—ã¦ãã ã•ã„ï¼")
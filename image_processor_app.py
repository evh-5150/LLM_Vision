import streamlit as st
import pydicom
import numpy as np
import cv2
from llama_cpp import Llama
import io
import inspect
import re

# --- å®šæ•°è¨­å®šã€AIãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã€ç”»åƒå‡¦ç†é–¢æ•°ç¾¤ã€FUNCTION_MAPã€LLMé€£æºé–¢æ•° ---
# --- å®šæ•°è¨­å®š ---
MODEL_PATH = "./Llama-3-ELYZA-JP-8B-Q4_K_M.gguf"
WINDOW_PRESETS = {
    "ã‚«ã‚¹ã‚¿ãƒ ": {}, "è…¹éƒ¨": {"ww": 400, "wl": 50}, "éª¨": {"ww": 2000, "wl": 600},
    "è‚º": {"ww": 1500, "wl": -600}, "è„³": {"ww": 80, "wl": 40},
}

PROCESSING_KNOWLEDGE = {
    "noise_removal": {"title": "ãƒã‚¤ã‚ºé™¤å»", "keywords": ["ãƒã‚¤ã‚º", "æ»‘ã‚‰ã‹", "ã‚¹ãƒ ãƒ¼ã‚º", "ã‚¶ãƒ©ã‚¶ãƒ©", "å¹³æ»‘åŒ–"]},
    "blur": {"title": "ã¼ã‹ã—", "keywords": ["ã¼ã‹ã—", "ãƒ–ãƒ©ãƒ¼", "å¹³æ»‘åŒ–"]},
    "edge_enhancement": {
        "title": "ã‚¨ãƒƒã‚¸å¼·èª¿",
        "keywords": ["ã‚¨ãƒƒã‚¸å¼·èª¿", "ã‚·ãƒ£ãƒ¼ãƒ—", "é®®æ˜", "ãã£ãã‚Š", "è¼ªéƒ­", "é®®é‹­åº¦", "é®®é‹­åŒ–", "ã‚·ãƒ£ãƒ¼ãƒ—ãƒã‚¹"]
    },
    "canny_edge": {"title": "ã‚¨ãƒƒã‚¸æ¤œå‡º", "keywords": ["ã‚¨ãƒƒã‚¸æ¤œå‡º", "å¢ƒç•ŒæŠ½å‡º", "ç·šç”»"]},
    "bilateral_filter": {
        "title": "ã‚¨ãƒƒã‚¸ä¿æŒå¹³æ»‘åŒ–",
        "keywords": ["ã‚¨ãƒƒã‚¸ä¿æŒ", "ã‚¨ãƒƒã‚¸ä¿æŒå¹³æ»‘åŒ–", "ãƒã‚¤ãƒ©ãƒ†ãƒ©ãƒ«", "bilateral", "è¼ªéƒ­ã‚’æ®‹ã—ã¦å¹³æ»‘åŒ–", "è¼ªéƒ­ã‚’æ®‹ã—ã¦ãƒã‚¤ã‚ºé™¤å»"]
    },
    "brightness_contrast": {"title": "æ˜ã‚‹ã•ãƒ»ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆ", "keywords": ["ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆ", "æ˜ã‚‹ã•", "æ˜ã‚‹ã", "æš—ã", "ç™½ã", "é»’ã", "è¦‹ã‚„ã™ã", "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦", "WW", "WL", "ãƒ¬ãƒ™ãƒ«"]},
    "thresholding": {"title": "äºŒå€¤åŒ–", "keywords": ["äºŒå€¤åŒ–", "é–¾å€¤", "ç™½é»’"]},
    "morphological": {"title": "å½¢æ…‹ç´ å¤‰æ›", "keywords": ["å½¢æ…‹ç´ ", "ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°", "ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°", "è†¨å¼µ", "åç¸®"]},
    "detect_bounding_box": {"title": "ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹æ¤œå‡º", "keywords": ["ãƒœãƒƒã‚¯ã‚¹", "å›²ã‚“ã§", "çŸ©å½¢", "å››è§’", "ç‰©ä½“æ¤œå‡º", "ãƒãƒ£ãƒ¼ãƒˆ"]},
    "detect_circles": {"title": "å††æ¤œå‡º", "keywords": ["å††æ¤œå‡º", "ä¸¸", "ã‚µãƒ¼ã‚¯ãƒ«"]},
    "zoom_in": {"title": "æ‹¡å¤§", "keywords": ["æ‹¡å¤§", "ã‚ºãƒ¼ãƒ ", "å¤§ãã", "ã‚¢ãƒƒãƒ—"]},
    "rotate": {"title": "å›è»¢", "keywords": ["å›è»¢", "å›ã—ã¦", "å‘ã"]},
    "flip": {"title": "åè»¢", "keywords": ["åè»¢", "è£è¿”ã—", "ãƒŸãƒ©ãƒ¼"]},
    "invert": {"title": "ãƒã‚¬ãƒã‚¸åè»¢", "keywords": ["ãƒã‚¬ãƒã‚¸", "è‰²ã‚’åè»¢", "éšèª¿åè»¢"]},
    "draw_contours": {"title": "è¼ªéƒ­æç”»", "keywords": ["è¼ªéƒ­ã‚’æç”»", "è¼ªéƒ­æŠ½å‡º"]}
}

# --- AIãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ ---
@st.cache_resource
def load_model():
    try:
        st.info("AIãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­ã§ã™ã€‚åˆå›èµ·å‹•æ™‚ã¯æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™...")
        llm = Llama(model_path=MODEL_PATH, n_gpu_layers=-1, n_ctx=4096, verbose=False, chat_format="llama-3")
        st.success("AIãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
        return llm
    except Exception as e:
        st.error(f"ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}ã€‚ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ« '{MODEL_PATH}' ãŒæ­£ã—ã„å ´æ‰€ã«ã‚ã‚Šã¾ã™ã‹ï¼Ÿ")
        return None
llm = load_model()

# --- ç”»åƒå‡¦ç†é–¢æ•°ç¾¤ ---
def process_noise_removal(img_in, kernel_size=5):
    k = int(kernel_size); return cv2.GaussianBlur(img_in, (k if k % 2 else k + 1, k if k % 2 else k + 1), 0)
def process_blur(img_in, kernel_size=9):
    k = int(kernel_size); return cv2.GaussianBlur(img_in, (k if k % 2 else k + 1, k if k % 2 else k + 1), 0)
def process_edge_enhancement(img_in, strength=1.5):
    img_float = img_in.astype(np.float64); blurred_float = cv2.GaussianBlur(img_float, (3, 3), 0)
    weight = float(strength) - 1.0; enhanced_float = np.clip(img_float + weight * (img_float - blurred_float), 0, 65535)
    return enhanced_float.astype(np.uint16)
def process_canny_edge(img_in, threshold1=100, threshold2=200):
    gray_8bit = cv2.normalize(img_in, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U); return cv2.Canny(gray_8bit, int(threshold1), int(threshold2))
def process_bilateral_filter(img_in, d=9, sigma_color=75.0, sigma_space=75.0):
    img_float32 = img_in.astype(np.float32) / 65535.0; sigma_color_normalized = sigma_color / 255.0
    filtered_float32 = cv2.bilateralFilter(img_float32, int(d), sigma_color_normalized, sigma_space); return np.clip(filtered_float32 * 65535.0, 0, 65535).astype(np.uint16)
def process_brightness_contrast(img_in, alpha=1.0, beta=0.0): return np.clip(img_in.astype(np.float64) * alpha + beta, 0, 65535).astype(np.uint16)
def process_thresholding(img_in, threshold_value=127.0):
    gray_8bit = cv2.normalize(img_in, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U); _, thresh_img = cv2.threshold(gray_8bit, int(threshold_value), 255, cv2.THRESH_BINARY); return thresh_img
def process_morphological(img_in, operation="ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°", kernel_size=5):
    gray_8bit = cv2.normalize(img_in, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U); kernel = np.ones((int(kernel_size), int(kernel_size)), np.uint8)
    op_map = {"ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°": cv2.MORPH_OPEN, "ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°": cv2.MORPH_CLOSE, "è†¨å¼µ": cv2.MORPH_DILATE, "åç¸®": cv2.MORPH_ERODE}; return cv2.morphologyEx(gray_8bit, op_map[operation], kernel)
def process_detect_bounding_box(img_in):
    output_img = cv2.normalize(img_in, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U); output_img = cv2.cvtColor(output_img, cv2.COLOR_GRAY2BGR)
    gray_8bit = output_img[:,:,0]; _, thresh = cv2.threshold(gray_8bit, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if contours: largest_contour = max(contours, key=cv2.contourArea); x, y, w, h = cv2.boundingRect(largest_contour); cv2.rectangle(output_img, (x, y), (x + w, y + h), (0, 255, 0), 3)
    return output_img
def process_detect_circles(img_in, dp=1.2, min_dist=100, param1=50, param2=30, min_radius=10, max_radius=100):
    output_img = cv2.normalize(img_in, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U); output_img = cv2.cvtColor(output_img, cv2.COLOR_GRAY2BGR)
    gray_8bit = output_img[:,:,0]; gray_8bit = cv2.medianBlur(gray_8bit, 5)
    circles = cv2.HoughCircles(gray_8bit, cv2.HOUGH_GRADIENT, dp=dp, minDist=min_dist, param1=param1, param2=param2, minRadius=min_radius, maxRadius=max_radius)
    if circles is not None:
        circles = np.uint16(np.around(circles));
        for i in circles[0, :]: center = (i[0], i[1]); radius = i[2]; cv2.circle(output_img, center, radius, (255, 0, 255), 3); cv2.circle(output_img, center, 2, (255, 255, 0), 3)
    return output_img
def process_zoom_in(img_in, scale=2.0, offset_x=0.0, offset_y=0.0):
    h, w = img_in.shape[:2]; center_x = w // 2 + int(offset_x * w / 2); center_y = h // 2 + int(offset_y * h / 2)
    new_w, new_h = int(w / scale), int(h / scale); x1 = max(0, center_x - new_w // 2); y1 = max(0, center_y - new_h // 2)
    x2, y2 = min(w, x1 + new_w), min(h, y1 + new_h)
    if x2 - x1 < new_w: x1 = x2 - new_w
    if y2 - y1 < new_h: y1 = y2 - new_h
    cropped = img_in[y1:y2, x1:x2]; return cv2.resize(cropped, (w, h), interpolation=cv2.INTER_LANCZOS4)
def process_rotate(img_in, angle="90åº¦ å³"):
    angle_map = {"90åº¦ å³": cv2.ROTATE_90_CLOCKWISE, "90åº¦ å·¦": cv2.ROTATE_90_COUNTERCLOCKWISE, "180åº¦": cv2.ROTATE_180}; return cv2.rotate(img_in, angle_map[angle])
def process_flip(img_in, direction="å·¦å³åè»¢"):
    flip_map = {"å·¦å³åè»¢": 1, "ä¸Šä¸‹åè»¢": 0, "ä¸¡æ–¹": -1}; return cv2.flip(img_in, flip_map[direction])
def process_invert(img_in):
    if img_in.dtype == np.uint16: return 65535 - img_in
    else: return 255 - img_in
def process_draw_contours(img_in, threshold=127.0, thickness=2):
    gray_8bit = cv2.normalize(img_in, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U); _, thresh_img = cv2.threshold(gray_8bit, int(threshold), 255, cv2.THRESH_BINARY)
    contours, _ = cv2.findContours(thresh_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE); output_img = cv2.cvtColor(gray_8bit, cv2.COLOR_GRAY2BGR)
    cv2.drawContours(output_img, contours, -1, (0, 255, 0), int(thickness)); return output_img

FUNCTION_MAP = {k: {"func": globals()[f"process_{k}"], **v} for k, v in PROCESSING_KNOWLEDGE.items()}

def get_tasks_from_llm(user_instruction):
    if llm is None:
        st.warning("AIãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã§ä»£ç”¨ã—ã¾ã™ã€‚");
        tasks = [name for name, info in FUNCTION_MAP.items() if any(keyword in user_instruction for keyword in info['keywords'])];
        return tasks if tasks else []

    task_list = "\n".join([f"- `{name}`: {info['title']}" for name, info in FUNCTION_MAP.items()])
    system_prompt = f"""ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŒ‡ç¤ºã‚’åˆ†æã—ã€å®Ÿè¡Œã™ã¹ãå‡¦ç†ã‚’é †ç•ªã«ç‰¹å®šã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆã‹ã‚‰é©åˆ‡ãªã‚¿ã‚¹ã‚¯åã‚’1ã¤ä»¥ä¸Šé¸ã³ã€ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®ãƒªã‚¹ãƒˆã¨ã—ã¦è¿”ç­”ã—ã¦ãã ã•ã„ã€‚

### ã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆ ###
{task_list}

### æŒ‡ç¤ºã¨å›ç­”ã®ä¾‹ ###
- æŒ‡ç¤º: ã€Œãƒã‚¤ã‚ºã‚’æ¶ˆã—ã¦ã€ -> å›ç­”: `noise_removal`
- æŒ‡ç¤º: ã€Œè¼ªéƒ­ã‚’ã¯ã£ãã‚Šã•ã›ã¦ã‹ã‚‰ã€ã‚¨ãƒƒã‚¸ã‚’æ¤œå‡ºã—ã¦ã€ -> å›ç­”: `edge_enhancement,canny_edge`
- æŒ‡ç¤º: ã€Œæ‹¡å¤§ã—ã¦ã€æ»‘ã‚‰ã‹ã«ã—ã¦ã»ã—ã„ã€ -> å›ç­”: `zoom_in,noise_removal`
- æŒ‡ç¤º: ã€Œç”»åƒã‚’å¹³æ»‘åŒ–ã—ã¦ã€ -> å›ç­”: `noise_removal`
"""
    messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_instruction}]
    try:
        output = llm.create_chat_completion(messages=messages, max_tokens=100, temperature=0.0)
        content = output['choices'][0]['message']['content'].strip()
        st.session_state.debug_llm_response = content
        all_task_names = list(FUNCTION_MAP.keys())
        pattern = r'\b(' + '|'.join(all_task_names) + r')\b'
        found_tasks = re.findall(pattern, content)
        return found_tasks if found_tasks else []
    except Exception as e:
        st.error(f"AIã®å¿œç­”å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"); return []

def convert_to_16bit_gray(pixel_array):
    if len(pixel_array.shape) > 2: pixel_array = cv2.cvtColor(pixel_array, cv2.COLOR_BGR2GRAY)
    if pixel_array.dtype != np.uint16: pixel_array = cv2.normalize(pixel_array.astype(float), None, 0, 65535, cv2.NORM_MINMAX).astype(np.uint16)
    return pixel_array
def apply_ww_wl_and_convert_to_bgr(pixel_array, ww, wl, enhance=False):
    if pixel_array is None: return None
    if pixel_array.dtype == np.uint8: return cv2.cvtColor(pixel_array, cv2.COLOR_GRAY2BGR) if len(pixel_array.shape) == 2 else pixel_array
    min_val, max_val = wl - (ww / 2), wl + (ww / 2); img_float = pixel_array.astype(np.float64); img_float = np.clip(img_float, min_val, max_val)
    if ww == 0: ww = 1
    img_8bit_gray = ((img_float - min_val) / ww * 255.0).astype(np.uint8)
    if enhance: clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)); img_8bit_gray = clahe.apply(img_8bit_gray)
    return cv2.cvtColor(img_8bit_gray, cv2.COLOR_GRAY2BGR)


st.set_page_config(layout="wide", page_title="LLM åŒ»ç”¨ç”»åƒå‡¦ç†")
st.title("LLM åŒ»ç”¨ç”»åƒå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ")

PARAM_CONFIG = {
    "noise_removal": {"kernel_size": {"label": "é™¤å»å¼·åº¦", "min": 3, "max": 41, "step": 2, "default": 15}},
    "blur": {"kernel_size": {"label": "ã¼ã‹ã—å¼·åº¦", "min": 3, "max": 41, "step": 2, "default": 15}},
    "edge_enhancement": {"strength": {"label": "å¼·èª¿åº¦", "min": 1.1, "max": 5.0, "step": 0.1, "default": 2.5}},
    "canny_edge": {"threshold1": {"label": "ä¸‹ä½é–¾å€¤", "min": 0, "max": 500, "default": 100}, "threshold2": {"label": "ä¸Šä½é–¾å€¤", "min": 0, "max": 500, "default": 200}},
    "bilateral_filter": {"d": {"label": "è¿‘å‚é ˜åŸŸã®ç›´å¾„", "min": 1, "max": 15, "step": 2, "default": 9}, "sigma_color": {"label": "è¼åº¦å·®ã®è¨±å®¹ç¯„å›²", "min": 1.0, "max": 255.0, "default": 75.0}, "sigma_space": {"label": "ç©ºé–“è·é›¢ã®è¨±å®¹ç¯„å›²", "min": 1.0, "max": 255.0, "default": 75.0}},
    "brightness_contrast": {"alpha": {"label": "ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆ", "min": 0.1, "max": 3.0, "step": 0.1, "default": 1.0}, "beta": {"label": "æ˜ã‚‹ã•", "min": -10000.0, "max": 10000.0, "step": 100.0, "default": 0.0}},
    "thresholding": {"threshold_value": {"label": "é–¾å€¤", "min": 0.0, "max": 255.0, "default": 127.0}},
    "morphological": {"operation": {"type": "selectbox", "label": "æ“ä½œã‚¿ã‚¤ãƒ—", "options": ["ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°", "ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°", "è†¨å¼µ", "åç¸®"], "default": "ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°"}, "kernel_size": {"label": "ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º", "min": 3, "max": 11, "step": 2, "default": 5}},
    "detect_circles": {"dp": {"label": "dp", "min": 1.0, "max": 2.0, "step": 0.1, "default": 1.2}, "min_dist": {"label": "å††åŒå£«ã®æœ€å°è·é›¢", "min": 10, "max": 200, "default": 100}, "param1": {"label": "Cannyä¸Šä½é–¾å€¤", "min": 10, "max": 200, "default": 50}, "param2": {"label": "æ¤œå‡ºæ„Ÿåº¦", "min": 10, "max": 100, "default": 30}, "min_radius": {"label": "æœ€å°åŠå¾„", "min": 0, "max": 200, "default": 10}, "max_radius": {"label": "æœ€å¤§åŠå¾„", "min": 0, "max": 500, "default": 100}},
    "zoom_in": {"scale": {"label": "æ‹¡å¤§ç‡", "min": 1.1, "max": 10.0, "step": 0.1, "default": 2.0}, "offset_x": {"label": "Xåº§æ¨™ã‚ªãƒ•ã‚»ãƒƒãƒˆ", "min": -1.0, "max": 1.0, "step": 0.05, "default": 0.0}, "offset_y": {"label": "Yåº§æ¨™ã‚ªãƒ•ã‚»ãƒƒãƒˆ", "min": -1.0, "max": 1.0, "step": 0.05, "default": 0.0}},
    "rotate": {"angle": {"type": "selectbox", "label": "å›è»¢è§’åº¦", "options": ["90åº¦ å³", "90åº¦ å·¦", "180åº¦"], "default": "90åº¦ å³"}},
    "flip": {"direction": {"type": "selectbox", "label": "åè»¢æ–¹å‘", "options": ["å·¦å³åè»¢", "ä¸Šä¸‹åè»¢", "ä¸¡æ–¹"], "default": "å·¦å³åè»¢"}},
    "draw_contours": {"threshold": {"label": "äºŒå€¤åŒ–é–¾å€¤", "min": 0.0, "max": 255.0, "default": 127.0}, "thickness": {"label": "è¼ªéƒ­ã®å¤ªã•", "min": 1, "max": 10, "default": 2}},
}
def reset_all_params_to_default():
    for task, params in PARAM_CONFIG.items():
        for param_name, config in params.items(): st.session_state[f"p_{task}_{param_name}"] = config["default"]

def handle_instruction_submit():
    """æŒ‡ç¤ºãŒé€ä¿¡ã•ã‚ŒãŸã¨ãã«å®Ÿè¡Œã•ã‚Œã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°"""
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’ã‚¯ãƒªã‚¢
    if 'debug_llm_response' in st.session_state:
        del st.session_state['debug_llm_response']

    instruction = st.session_state.get("instruction_input", "").strip()

    if not instruction:
        # å…¥åŠ›ãŒç©ºãªã‚‰å‡¦ç†ã‚’ãƒªã‚»ãƒƒãƒˆ
        st.session_state.last_tasks = []
        reset_all_params_to_default() # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å†…ãªã®ã§å®‰å…¨
        st.toast("ç”»åƒå‡¦ç†ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸã€‚")
    else:
        # AIã§ã‚¿ã‚¹ã‚¯ã‚’è§£æ
        st.toast("AIãŒã‚¿ã‚¹ã‚¯ã‚’è§£æä¸­...")
        task_names = get_tasks_from_llm(instruction)
        
        # æ–°ã—ã„ã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆã®å ´åˆã®ã¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ
        if st.session_state.get("last_tasks", []) != task_names:
            reset_all_params_to_default() # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å†…ãªã®ã§å®‰å…¨

        st.session_state.last_tasks = task_names
        
        if task_names:
            titles = " â†’ ".join([FUNCTION_MAP[t]['title'] for t in task_names])
            st.toast(f"âœ… ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­å®š: {titles}")
        else:
            # ã‚¨ãƒ©ãƒ¼ã¯UIå´ã§è¡¨ç¤ºã™ã‚‹ãŸã‚ã«ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
            st.session_state.show_task_not_found_error = True

# --- çŠ¶æ…‹ã®åˆæœŸåŒ– ---
if "initialized" not in st.session_state:
    st.session_state.initialized = True
    st.session_state.last_tasks = []
    st.session_state.last_file_id = None
    st.session_state.p_ww = 400.0
    st.session_state.p_wl = 50.0
    st.session_state.preset = "ã‚«ã‚¹ã‚¿ãƒ "
    reset_all_params_to_default()

# --- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨DICOMèª­ã¿è¾¼ã¿ ---
uploaded_file = st.file_uploader("16-bit DICOMç”»åƒã‚’é¸æŠ", type=["dcm", "dicom"])
original_16bit_gray = None
if uploaded_file:
    if st.session_state.last_file_id != uploaded_file.file_id:
        st.session_state.last_tasks = []
        st.session_state.dicom_ww_wl_initialized = False
        if 'instruction_input' in st.session_state: st.session_state.instruction_input = ""
        st.session_state.last_file_id = uploaded_file.file_id
    try:
        ds = pydicom.dcmread(io.BytesIO(uploaded_file.getvalue()))
        pixel_array = ds.pixel_array * ds.get("RescaleSlope", 1) + ds.get("RescaleIntercept", 0)
        original_16bit_gray = convert_to_16bit_gray(pixel_array)
        if not st.session_state.get('dicom_ww_wl_initialized', False):
            try:
                wl_val = ds.WindowCenter[0] if isinstance(ds.WindowCenter, pydicom.multival.MultiValue) else ds.WindowCenter
                ww_val = ds.WindowWidth[0] if isinstance(ds.WindowWidth, pydicom.multival.MultiValue) else ds.WindowWidth
                st.session_state.initial_wl, st.session_state.initial_ww = float(wl_val), float(ww_val)
            except (AttributeError, TypeError, IndexError):
                min_val, max_val = np.min(original_16bit_gray), np.max(original_16bit_gray)
                st.session_state.initial_ww = float(max_val - min_val if max_val > min_val else 1)
                st.session_state.initial_wl = float(min_val + st.session_state.initial_ww / 2)
            
            # WW/WLã®åˆæœŸå€¤ã‚’è¨­å®š
            st.session_state.p_wl, st.session_state.p_ww = st.session_state.initial_wl, st.session_state.initial_ww
            st.session_state.p_wl_slider, st.session_state.p_ww_slider = st.session_state.initial_wl, st.session_state.initial_ww
            st.session_state.dicom_ww_wl_initialized = True
    except Exception as e:
        st.error(f"DICOMèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        original_16bit_gray = None

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼UI ---
with st.sidebar:
    st.header("ğŸ–¼ï¸ è¡¨ç¤ºã‚ªãƒ—ã‚·ãƒ§ãƒ³")
    enhance_default = st.checkbox("ç”»è³ªã‚’å‘ä¸Šã•ã›ã‚‹ (CLAHE)", value=False)
    st.header("è¡¨ç¤ºèª¿æ•´ (WW/WL)")
    is_disabled = (original_16bit_gray is None)
    
    def reset_ww_wl():
        if "initial_ww" in st.session_state and "initial_wl" in st.session_state:
            st.session_state.p_ww, st.session_state.p_wl = st.session_state.initial_ww, st.session_state.initial_wl
            st.session_state.p_ww_slider, st.session_state.p_wl_slider = st.session_state.initial_ww, st.session_state.initial_wl

    def on_preset_change():
        preset_key = st.session_state.preset
        if preset_key != "ã‚«ã‚¹ã‚¿ãƒ " and preset_key in WINDOW_PRESETS:
            st.session_state.p_ww, st.session_state.p_wl = float(WINDOW_PRESETS[preset_key]["ww"]), float(WINDOW_PRESETS[preset_key]["wl"])
            # ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚‚åŒæœŸ
            st.session_state.p_ww_slider, st.session_state.p_wl_slider = st.session_state.p_ww, st.session_state.p_wl

    st.selectbox("ãƒ—ãƒªã‚»ãƒƒãƒˆ", list(WINDOW_PRESETS.keys()), key="preset", on_change=on_preset_change, disabled=is_disabled)

    WW_MIN, WW_MAX, WL_MIN, WL_MAX = 1.0, 65536.0, -32768.0, 65536.0
    
    def sync_ww_from_slider(): st.session_state.p_ww = st.session_state.p_ww_slider; st.session_state.preset = "ã‚«ã‚¹ã‚¿ãƒ "
    def sync_ww_from_number_input(): st.session_state.p_ww_slider = st.session_state.p_ww
    def sync_wl_from_slider(): st.session_state.p_wl = st.session_state.p_wl_slider; st.session_state.preset = "ã‚«ã‚¹ã‚¿ãƒ "
    def sync_wl_from_number_input(): st.session_state.p_wl_slider = st.session_state.p_wl

    if 'p_ww_slider' not in st.session_state: st.session_state.p_ww_slider = st.session_state.p_ww
    if 'p_wl_slider' not in st.session_state: st.session_state.p_wl_slider = st.session_state.p_wl

    col1, col2 = st.columns([0.4, 0.6])
    with col1: st.number_input("WW", WW_MIN, WW_MAX, key="p_ww", disabled=is_disabled, step=10.0, format="%.1f", on_change=sync_ww_from_number_input)
    with col2: st.slider(" ", WW_MIN, WW_MAX, key="p_ww_slider", label_visibility="collapsed", disabled=is_disabled, on_change=sync_ww_from_slider)
    col3, col4 = st.columns([0.4, 0.6])
    with col3: st.number_input("WL", WL_MIN, WL_MAX, key="p_wl", disabled=is_disabled, step=10.0, format="%.1f", on_change=sync_wl_from_number_input)
    with col4: st.slider(" ", WL_MIN, WL_MAX, key="p_wl_slider", label_visibility="collapsed", disabled=is_disabled, on_change=sync_wl_from_slider)
    st.button("WW/WLã‚’åˆæœŸå€¤ã«æˆ»ã™", on_click=reset_ww_wl, disabled=is_disabled, use_container_width=True)
    
    st.header("âš™ï¸ å‡¦ç†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´")
    tasks = st.session_state.get("last_tasks", [])
    if original_16bit_gray is not None and tasks:
        for i, task in enumerate(tasks):
            task_config = PARAM_CONFIG.get(task)
            with st.expander(f"ã‚¹ãƒ†ãƒƒãƒ— {i+1}: {FUNCTION_MAP[task]['title']}", expanded=True):
                if task_config:
                    for param_name, config in task_config.items():
                        session_key = f"p_{task}_{param_name}"
                        if config.get("type") == "selectbox": st.selectbox(config["label"], config["options"], key=session_key)
                        else: st.slider(config["label"], config["min"], config["max"], step=config.get("step", 0.1 if isinstance(config["min"], float) else 1), key=session_key)
                else: st.info("èª¿æ•´å¯èƒ½ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        st.button("å…¨ã¦ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’åˆæœŸå€¤ã«æˆ»ã™", on_click=reset_all_params_to_default, use_container_width=True)
    else: st.info("å‡¦ç†ã‚’é¸æŠã™ã‚‹ã¨ã€èª¿æ•´é …ç›®ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

# --- ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ã®UIã¨å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯ ---
if original_16bit_gray is not None:
    st.text_input(
        "ç”»åƒå‡¦ç†ã®æŒ‡ç¤º",
        placeholder="ä¾‹: æ‹¡å¤§ã—ã¦å¹³æ»‘åŒ– / ç©ºæ¬„ã§ãƒªã‚»ãƒƒãƒˆ",
        key="instruction_input",
        label_visibility="collapsed",
        on_change=handle_instruction_submit # Enterã‚­ãƒ¼ã§ã‚‚ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãŒå‘¼ã°ã‚Œã‚‹ã‚ˆã†ã«
    )
    st.button(
        label='ç”»åƒå‡¦ç†ã‚’å®Ÿè¡Œ',
        use_container_width=True,
        disabled=(llm is None),
        on_click=handle_instruction_submit # ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯ã§ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å‘¼ã¶
    )
    
    # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§ã‚»ãƒƒãƒˆã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼ãƒ•ãƒ©ã‚°ã‚’ãƒã‚§ãƒƒã‚¯
    if st.session_state.get("show_task_not_found_error", False):
        st.error("æŒ‡ç¤ºå†…å®¹ã«å¯¾å¿œã™ã‚‹å‡¦ç†ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.session_state.show_task_not_found_error = False # ä¸€åº¦è¡¨ç¤ºã—ãŸã‚‰ãƒ•ãƒ©ã‚°ã‚’ä¸‹ã’ã‚‹
    
    if 'debug_llm_response' in st.session_state and st.session_state.debug_llm_response:
        with st.expander("ãƒ‡ãƒãƒƒã‚°æƒ…å ±: AIã‹ã‚‰ã®ç”Ÿã®å¿œç­”"):
            st.text(st.session_state.debug_llm_response)

    if llm is None: st.warning("AIãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€æŒ‡ç¤ºã«ã‚ˆã‚‹ç”»åƒå‡¦ç†ã¯ç„¡åŠ¹ã§ã™ã€‚")

    tasks_to_run = st.session_state.get("last_tasks", [])
    display_original_image = original_16bit_gray
    if tasks_to_run and tasks_to_run[0] == 'zoom_in':
        zoom_params = {p_name: st.session_state[f"p_zoom_in_{p_name}"]
                       for p_name in inspect.signature(process_zoom_in).parameters
                       if p_name != 'img_in' and f"p_zoom_in_{p_name}" in st.session_state}
        display_original_image = process_zoom_in(original_16bit_gray, **zoom_params)

    processed_image = original_16bit_gray
    header_text = "å‡¦ç†å¾Œ"
    if tasks_to_run:
        header_text = f"å‡¦ç†å¾Œ: " + " â†’ ".join([FUNCTION_MAP[t]['title'] for t in tasks_to_run])
        temp_image = original_16bit_gray.copy()
        try:
            for task in tasks_to_run:
                processing_function = FUNCTION_MAP[task]["func"]
                params_to_pass = {param_name: st.session_state[f"p_{task}_{param_name}"]
                                  for param_name in inspect.signature(processing_function).parameters
                                  if param_name != 'img_in' and f"p_{task}_{param_name}" in st.session_state}
                temp_image = processing_function(temp_image, **params_to_pass)
            processed_image = temp_image
        except Exception as e:
            st.error(f"ç”»åƒå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"); st.exception(e)
            
    col1, col2 = st.columns(2)
    ww, wl = st.session_state.p_ww, st.session_state.p_wl
    with col1:
        st.header("å‡¦ç†å‰")
        st.image(apply_ww_wl_and_convert_to_bgr(display_original_image, ww, wl, enhance=enhance_default), use_container_width=True)
    with col2:
        st.header(header_text)
        st.image(apply_ww_wl_and_convert_to_bgr(processed_image, ww, wl, enhance=enhance_default), use_container_width=True)
else:
    if not uploaded_file: st.info("DICOMãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€ç”»åƒå‡¦ç†ã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")